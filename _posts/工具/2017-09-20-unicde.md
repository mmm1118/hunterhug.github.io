---
layout: post
title: "转载:字符集和大小端"
date: 2017-09-20
author: silly
desc: "编码、解码、乱码、Unicode、UCS-2、UCS-4、UTF-8、UTF-16、Big Endian、Little Endian、GBK这些名词，如果你有一个不太清楚，那么建议看看本文。"
categories: ["工具"]
tags: ["unicode"]
permalink: "/tool/unicode.html"
--- 

来自: https://zhuanlan.zhihu.com/p/25435644

我觉得写得很好

# 1. 前言

编码、解码、乱码、Unicode、UCS-2、UCS-4、UTF-8、UTF-16、Big Endian、Little Endian、GBK这些名词，如果你有一个不太清楚，那么建议看看本文。

# 2. 一幅图说尽Java编码问题

## 2.1 一幅图与四个概念

字符有三种形态：形状（显示在显示设备上）、数字（运行于JVM中，Java统一为unicode编码）和字节数组（不同的字符集有不同的映射方案）。
如此就可以明白四个重要的实体概念了（这四个概念来自于《Java NIO》一书）：

字符集合（Character set）：是一组形状的集合，例如所有汉字的集合，发明于公元前，发明者是仓颉。它体现了字符的“形状”，它与计算机、编码等无关。

编码字符集（Coded character set）：是一组字符对应的编码（即数字），为字符集合中的每一个字符给予一个数字。例如最早的编码字符集ASCII，发明于1967年。再例如Java使用的unicode，发明于1994年（持续更新中）。由于编码字符集为每一个字符赋予一个数字，因此在java内部，字符可以认为就是一个16位的数字，因此以下方式都可以给字符赋值：

	char c=‘中’
	char c =0x4e2d
	char c=20013

字符编码方案（Character-encoding schema）：将字符编码（数字）映射到一个字节数组的方案，因为在磁盘里，所有信息都是以字节的方式存储的。因此Java的16位字符必须转换为一个字节数组才能够存储。例如UTF-8字符编码方案，它可以将一个字符转换为1、2、3或者4个字节。

一般认为，编码字符集和字符编码方案合起来被称之为字符集（Charset），这是一个术语，要和前面的字符集合（Character set）区分开。

# 2.2 转换的类型

## 2.2.1. 从数字到形状—字体库

从JVM中的字符编码，到屏幕上显示的形状。这个转换是在字体库的帮助下完成的。例如windows默认的一些汉字字体，在Java中运行时是一个个的数字编码，例如0x4e2d，通过查找字体库，得到一个形状“中”，然后显示在屏幕上。

## 2.2.2. 从数字到字节数组—编码

从JVM中的编码，到字节数组，这个转换被称之为编码。转换的目的是为了存储，或者发送信息。

同一个数字，例如0x4e2d，采用不同的字符集进行编码，能得到不同的字节数组。如图中所见。

至于具体的UTF-8、GBK、UTF-16等字符集的历史渊源，具体转换方式都有很多的资料可以查询。

编码的例子代码如下：

第一种方法，使用String的getBytes方法：

	private static byte[] encoding1(String str, String charset) throws UnsupportedEncodingException {
		return str.getBytes(charset);
	}

第二种方法，使用Charset的encode方法：

		private static byte[] encoding2(String str, String charset) {
		    Charset cset = Charset.forName(charset);
		    ByteBuffer byteBuffer = cset.encode(str);
		    byte[] bytes = new byte[byteBuffer.remaining()];
		    byteBuffer.get(bytes);
		    return bytes;
	}

注意：Charset、ByteBuffer以及后文中提到的CharBuffer类都是Java NIO包中的类，具体使用方法可参考《Java NIO》一书。

## 2.2.3. 从字节数组到数字—解码

从一个字节数组，到一个代表字符的数字，这个转换被称之为解码。解码一般是将从磁盘或者网络上得到的信息，转换为字符或字符串。

注意解码时一定要指定字符集，否则将会使用默认的字符集进行解码。如果使用了错误的字符集，则会出现乱码。

解码的例子代码如下：

第一种方法，使用String的构造函数：

	private static String decoding1(byte[] bytes,String charset) throws UnsupportedEncodingException {
		    String str = new String(bytes, charset);
		    return str;
		}

第二种方法，使用Charset的decode方法：

		   private static String decoding2(byte[] bytes, String charset) {
		    Charset cset = Charset.forName(charset);
		    ByteBuffer buffer = ByteBuffer.wrap(bytes);
		    CharBuffer charBuffer = cset.decode(buffer);
		    return charBuffer.toString();
		}

## 2.3 默认的字符集

乱码问题都是因为在编码或者解码时使用了错误的字符集导致的。如果不能明白什么是默认的字符集，则很有可能导致乱码。

Java的默认字符集，可以在两个地方设定，一是执行java程序时使用-Dfile.encoding参数指定，例如-Dfile.encoding=UTF-8就指定默认字符集是UTF-8。二是在程序执行时使用Properties进行指定，如下：

	private static void setEncoding(String charset) {
		Properties properties = System.getProperties();
		properties.put("file.encoding",charset);
		System.out.println(properties.get("file.encoding"));
	}

注意，这两种方法如果同时使用，则程序开始时使用参数指定的字符集，在Properties方法后使用Properties指定的字符集。

如果这两种方法都没有使用，则使用操作系统默认的字符集。例如中文版windows 7的默认字符集是GBK。

默认字符集的优先级如下：

1. 程序执行时使用Properties指定的字符集；
2. java命令的-Dfile.encoding参数指定的字符集；
3. 操作系统默认的字符集；
4. JDK中默认的字符集，我跟踪了JDK1.8的源代码，发现其默认字符集指定为ISO-8859-1。

## 2.3.1. JDK支持的字符集

Charset类提供了一个方法可以列出当前JDK所支持的所有字符集，代码如下：

	private static void printAvailableCharsets() {
		Map<String ,Charset> map = Charset.availableCharsets();
		System.out.println("the available Charsets supported by jdk:"+map.size());
		for (Map.Entry<String, Charset> entry :
		        map.entrySet()) {
		    System.out.println(entry.getKey());
		}
	}

本测试机使用的JDK为1.8，列出的字符集多达169个。

# 3. 乱码

## 3.1 如何产生乱码

从上述章节可知，字符的形态有三种，分别是“形状”、“数字”和“字节”。字符的三种形态之间的转换也有三类：从数字到形状，从数字到字节（编码），从字节到数字（解码）。

从数字到形状不会产生乱码，乱码就产生在编码和解码的时候。仔细想来，编码也是不会产生乱码的，因为从数字到字节（指定某个字符集）一定能够转换成功，即使某字符集中不包含该数字，它也会用指定的字节来代替，并在转换时给出指示。

如此一来，乱码只会产生在解码时：例如使用某字符集A编码的字节，使用字符集B来进行解码，而A和B并不兼容。这样一来，解码产生的数字（字符编码）就是错误的，那么它显示出来也是错误的，典型的乱码例子如下（使用UTF-8编码，使用GBK解码）：

	private static void generateGrabledCode() throws UnsupportedEncodingException {
		String str = "中国";
		byte[] bytes = str.getBytes("UTF-8");
		str = new String(bytes, "GBK");
		System.out.println(str);
	}

# 4. 再论Unicode、UTF和GBK

弄清楚了以上的概念和例子，再来看unicode、UCS-2、UCS-4、UTF-8、UTF-16、Big Endian、Little Endian、GBK这些名词就有了辨别的好方法了
。
再复习一遍概念：

字符集合（Character set）：是一组形状的集合，一般存储于字库中。

编码字符集（Coded character set）：是一组字符对应的编码（即数字），为字符集合中的每一个字符给予一个数字。

字符编码方案（Character-encoding schema）：将字符编码（数字）映射到一个字节数组的方案。

字符集（Charset）：是编码字符集和字符编码方案的组合。

## 4.1 Unicode是一个编码字符集

Unicode的全称是“Universal Multiple-Octet Coded Character Set”，通用多字节编码字符集，简写为UCS。

因此我们知道：Unicode规定了一组字符对应的编码。恰好这组字符就是全人类目前所有的字符。

那么UCS-2和UCS-4是什么意思？UCS-2是指用两个字节对应一个字符的编码字符集；UCS-4则是指用四个字节对应一个字符的编码字符集。你可以认为，目前为止Unicode有两个具体的编码字符集，UCS-2和UCS-4。

Java使用的是UCS-2，即我们前面提到的，一个字符由一个16位的二进制数（2个字节）表示。

## 4.2 UTF是字符编码方案

看过很多文章，往往混淆Unicode和UTF，说不清它们之间的区别，用本文的概念很容易就解释清楚了。

Unicode是某种编码字符集（目前包括UCS-2和UCS-4两种），而UTF则是字符编码方案，就是将字符编码（数字）映射到一个字节数组的方案。UTF中的U是指Unicode，也就是将Unicode编码映射到字节数组的方案。目前UTF包括UTF-7、UTF-8、UTF-16和UTF-32，后面的数字代表转换时最小的位数。例如UTF-8就是用几个8位二进制数来代表一个Unicode编码。而UTF-15就是用几个16位二进制数来代表一个Unicode编码。

## 4.3 Big Endian和Little Endian是字节序

字节序就是数据在内存中存放的顺序，多于一个字节的数据在内存中存放时有两种选择，即Big Endian和Little Endian。

Little-Endian就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。

Big-Endian就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。

Big Endian和Little Endian和芯片类型以及操作系统都有关系。但是由于Java是平台无关的，所以Java被设计为Big Endian的。但是当Java中的字符进行编码时，就要注意其字节序了。

例如UTF-16字符编码方案就分为UTF-16BE和UTF-16LE。

## 4.4 GBK是一个字符集

GBK同时包含编码字符集和字符编码方案。GBK编码了目前使用的大多数汉字（编码字符集），它将每一个汉字映射为两个字节，对于英文和数字，它则使用与ASCII相同的一个字节编码（字符编码方案）。

# 5. 小结

编码、解码和乱码问题，永远是程序员的梦魇。看懂一幅图，弄明白四个概念，也许有助于一劳永逸的解决此问题。

# 彩蛋: 大小端

参见: http://www.cnblogs.com/ciaos/p/4622165.html

```
一、大端模式和小端模式的起源

        关于大端小端名词的由来，有一个有趣的故事，来自于Jonathan Swift的《格利佛游记》：Lilliput和Blefuscu这两个强国在过去的36个月中一直在苦战。战争的原因：大家都知道，吃鸡蛋的时候，原始的方法是打破鸡蛋较大的一端，可以那时的皇帝的祖父由于小时侯吃鸡蛋，按这种方法把手指弄破了，因此他的父亲，就下令，命令所有的子民吃鸡蛋的时候，必须先打破鸡蛋较小的一端，违令者重罚。然后老百姓对此法令极为反感，期间发生了多次叛乱，其中一个皇帝因此送命，另一个丢了王位，产生叛乱的原因就是另一个国家Blefuscu的国王大臣煽动起来的，叛乱平息后，就逃到这个帝国避难。据估计，先后几次有11000余人情愿死也不肯去打破鸡蛋较小的端吃鸡蛋。这个其实讽刺当时英国和法国之间持续的冲突。Danny Cohen一位网络协议的开创者，第一次使用这两个术语指代字节顺序，后来就被大家广泛接受。
二、什么是大端和小端

        Big-Endian和Little-Endian的定义如下：
1) Little-Endian就是低位字节排放在内存的低地址端，高位字节排放在内存的高地址端。
2) Big-Endian就是高位字节排放在内存的低地址端，低位字节排放在内存的高地址端。
举一个例子，比如数字0x12 34 56 78在内存中的表示形式为：

1)大端模式：

低地址 -----------------> 高地址
0x12  |  0x34  |  0x56  |  0x78

2)小端模式：

低地址 ------------------> 高地址
0x78  |  0x56  |  0x34  |  0x12

可见，大端模式和字符串的存储模式类似。

3)下面是两个具体例子：
16bit宽的数0x1234在Little-endian模式（以及Big-endian模式）CPU内存中的存放方式（假设从地址0x4000开始存放）为：
内存地址 	小端模式存放内容 	大端模式存放内容
0x4000 	0x34 	0x12
0x4001 	0x12 	0x34

32bit宽的数0x12345678在Little-endian模式以及Big-endian模式）CPU内存中的存放方式（假设从地址0x4000开始存放）为：
内存地址 	小端模式存放内容 	大端模式存放内容
0x4000 	0x78 	0x12
0x4001 	0x56 	0x34
0x4002 	0x34 	0x56
0x4003 	0x12 	0x78
4)大端小端没有谁优谁劣，各自优势便是对方劣势：

小端模式 ：强制转换数据不需要调整字节内容，1、2、4字节的存储方式一样。
大端模式 ：符号位的判定固定为第一个字节，容易判断正负。
三、数组在大端小端情况下的存储：

　　以unsigned int value = 0x12345678为例，分别看看在两种字节序下其存储情况，我们可以用unsigned char buf[4]来表示value：
　　Big-Endian: 低地址存放高位，如下：
高地址
        ---------------
        buf[3] (0x78) -- 低位
        buf[2] (0x56)
        buf[1] (0x34)
        buf[0] (0x12) -- 高位
        ---------------
        低地址
Little-Endian: 低地址存放低位，如下：
高地址
        ---------------
        buf[3] (0x12) -- 高位
        buf[2] (0x34)
        buf[1] (0x56)
        buf[0] (0x78) -- 低位
        --------------
低地址
四、为什么会有大小端模式之分呢？

      这是因为在计算机系统中，我们是以字节为单位的，每个地址单元都对应着一个字节，一个字节为8bit。但是在C语言中除了8bit的char之外，还有16bit的short型，32bit的long型（要看具体的编译器），另外，对于位数大于8位的处理器，例如16位或者32位的处理器，由于寄存器宽度大于一个字节，那么必然存在着一个如果将多个字节安排的问题。因此就导致了大端存储模式和小端存储模式。例如一个16bit的short型x，在内存中的地址为0x0010，x的值为0x1122，那么0x11为高字节，0x22为低字节。对于大端模式，就将0x11放在低地址中，即0x0010中，0x22放在高地址中，即0x0011中。小端模式，刚好相反。我们常用的X86结构是小端模式，而KEIL C51则为大端模式。很多的ARM，DSP都为小端模式。有些ARM处理器还可以由硬件来选择是大端模式还是小端模式。
五、如何判断机器的字节序

可以编写一个小的测试程序来判断机器的字节序：
复制代码

BOOL IsBigEndian()  
{  
    int a = 0x1234;  
    char b =  *(char *)&a;  //通过将int强制类型转换成char单字节，通过判断起始存储位置。即等于 取b等于a的低地址部分  
    if( b == 0x12)  
    {  
        return TRUE;  
    }  
    return FALSE;  
}

复制代码

联合体union的存放顺序是所有成员都从低地址开始存放，利用该特性可以轻松地获得了CPU对内存采用Little-endian还是Big-endian模式读写：
复制代码

BOOL IsBigEndian()  
{  
    union NUM  
    {  
        int a;  
        char b;  
    }num;  
    num.a = 0x1234;  
    if( num.b == 0x12 )  
    {  
        return TRUE;  
    }  
    return FALSE;  
}

复制代码
六、常见的字节序

一般操作系统都是小端，而通讯协议是大端的。
4.1 常见CPU的字节序

Big Endian : PowerPC、IBM、Sun
Little Endian : x86、DEC
ARM既可以工作在大端模式，也可以工作在小端模式。
4.2 常见文件的字节序

Adobe PS – Big Endian
BMP – Little Endian
DXF(AutoCAD) – Variable
GIF – Little Endian
JPEG – Big Endian
MacPaint – Big Endian
RTF – Little Endian
 
另外，Java和所有的网络通讯协议都是使用Big-Endian的编码。
 
七、如何进行转换

对于字数据（16位）：
 

    #define BigtoLittle16(A)   (( ((uint16)(A) & 0xff00) >> 8)    | \  
                                           (( (uint16)(A) & 0x00ff) << 8))  

对于双字数据（32位）：
 

    #define BigtoLittle32(A)   ((( (uint32)(A) & 0xff000000) >> 24) | \  
                                           (( (uint32)(A) & 0x00ff0000) >> 8)   | \  
                                           (( (uint32)(A) & 0x0000ff00) << 8)   | \  
                                           (( (uint32)(A) & 0x000000ff) << 24))  

 
八、从软件的角度理解端模式

        从软件的角度上，不同端模式的处理器进行数据传递时必须要考虑端模式的不同。如进行网络数据传递时，必须要考虑端模式的转换。在Socket接口编程中，以下几个函数用于大小端字节序的转换。

    #define ntohs(n)     //16位数据类型网络字节顺序到主机字节顺序的转换  
    #define htons(n)     //16位数据类型主机字节顺序到网络字节顺序的转换  
    #define ntohl(n)      //32位数据类型网络字节顺序到主机字节顺序的转换  
    #define htonl(n)      //32位数据类型主机字节顺序到网络字节顺序的转换  


其中互联网使用的网络字节顺序采用大端模式进行编址，而主机字节顺序根据处理器的不同而不同，如PowerPC处理器使用大端模式，而Pentuim处理器使用小端模式。
       大端模式处理器的字节序到网络字节序不需要转换，此时ntohs(n)=n，ntohl = n；而小端模式处理器的字节序到网络字节必须要进行转换，此时ntohs(n) = __swab16(n)，ntohl = __swab32(n)。__swab16与__swab32函数定义如下所示。
复制代码

#define ___swab16(x)  
{  
            __u16 __x = (x);  
            ((__u16)(  
                        (((__u16)(__x) & (__u16)0x00ffU) << 8) |  
                        (((__u16)(__x) & (__u16)0xff00U) >> 8) ));  
}  
  
  
#define ___swab32(x)  
{  
            __u32 __x = (x);  
            ((__u32)(  
                        (((__u32)(__x) & (__u32)0x000000ffUL) << 24) |  
                        (((__u32)(__x) & (__u32)0x0000ff00UL) << 8) |  
                        (((__u32)(__x) & (__u32)0x00ff0000UL) >> 8) |  
                        (((__u32)(__x) & (__u32)0xff000000UL) >> 24) ));  
}  

复制代码

        PowerPC处理器提供了lwbrx，lhbrx，stwbrx，sthbrx四条指令用于处理字节序的转换以优化__swab16和__swap32这类函数。此外PowerPC处理器中的rlwimi指令也可以用来实现__swab16和__swap32这类函数。

       在对普通文件进行处理也需要考虑端模式问题。在大端模式的处理器下对文件的32，16位读写操作所得到的结果与小端模式的处理器不同。单纯从软件的角度理解上远远不能真正理解大小端模式的区别。事实上，真正的理解大小端模式的区别，必须要从系统的角度，从指令集，寄存器和数据总线上深入理解，大小端模式的区别。
九、从系统的角度理解端模式
先补充两个关键词，MSB和LSB：
　　MSB:MoST Significant Bit ------- 最高有效位
        LSB:Least Significant Bit ------- 最低有效位
 

        处理器在硬件上由于端模式问题在设计中有所不同。从系统的角度上看，端模式问题对软件和硬件的设计带来了不同的影响，当一个处理器系统中大小端模式同时存在时，必须要对这些不同端模式的访问进行特殊的处理。
       PowerPC处理器主导网络市场，可以说绝大多数的通信设备都使用PowerPC处理器进行协议处理和其他控制信息的处理，这也可能也是在网络上的绝大多数协议都采用大端编址方式的原因。因此在有关网络协议的软件设计中，使用小端方式的处理器需要在软件中处理端模式的转变。而Pentium主导个人机市场，因此多数用于个人机的外设都采用小端模式，包括一些在网络设备中使用的PCI总线，Flash等设备，这也要求在硬件设计中注意端模式的转换。
       本文提到的小端外设是指这种外设中的寄存器以小端方式进行存储，如PCI设备的配置空间，NOR FLASH中的寄存器等等。对于有些设备，如DDR颗粒，没有以小端方式存储的寄存器，因此从逻辑上讲并不需要对端模式进行转换。在设计中，只需要将双方数据总线进行一一对应的互连，而不需要进行数据总线的转换。
       如果从实际应用的角度说，采用小端模式的处理器需要在软件中处理端模式的转换，因为采用小端模式的处理器在与小端外设互连时，不需要任何转换。而采用大端模式的处理器需要在硬件设计时处理端模式的转换。大端模式处理器需要在寄存器，指令集，数据总线及数据总线与小端外设的连接等等多个方面进行处理，以解决与小端外设连接时的端模式转换问题。在寄存器和数据总线的位序定义上，基于大小端模式的处理器有所不同。
       一个采用大端模式的32位处理器，如基于E500内核的MPC8541，将其寄存器的最高位msb（most significant bit）定义为0，最低位lsb（lease significant bit）定义为31；而小端模式的32位处理器，将其寄存器的最高位定义为31，低位地址定义为0。与此向对应，采用大端模式的32位处理器数据总线的最高位为0，最高位为31；采用小端模式的32位处理器的数据总线的最高位为31，最低位为0。         
       大小端模式处理器外部总线的位序也遵循着同样的规律，根据所采用的数据总线是32位，16位和8位，大小端处理器外部总线的位序有所不同。大端模式下32位数据总线的msb是第0位，MSB是数据总线的第0~7的字段；而lsb是第31位，LSB是第24~31字段。小端模式下32位总线的msb是第31位，MSB是数据总线的第31~24位，lsb是第0位，LSB是7~0字段。大端模式下16位数据总线的msb是第0位，MSB是数据总线的第0~7的字段；而lsb是第15位，LSB是第8~15字段。小端模式下16位总线的msb是第15位，MSB是数据总线的第15~7位，lsb是第0位，LSB是7~0字段。大端模式下8位数据总线的msb是第0位，MSB是数据总线的第0~7的字段；而lsb是第7位，LSB是第0~7字段。小端模式下8位总线的msb是第7位，MSB是数据总线的第7~0位，lsb是第0位，LSB是7~0字段。
         由上分析，我们可以得知对于8位，16位和32位宽度的数据总线，采用大端模式时数据总线的msb和MSB的位置都不会发生变化，而采用小端模式时数据总线的lsb和LSB位置也不会发生变化。
         为此，大端模式的处理器对8位，16位和32位的内存访问（包括外设的访问）一般都包含第0~7字段，即MSB。小端模式的处理器对8位，16位和32位的内存访问都包含第7~0位，小端方式的第7~0字段，即LSB。由于大小端处理器的数据总线其8位，16位和32位宽度的数据总线的定义不同，因此需要分别进行讨论在系统级别上如何处理端模式转换。在一个大端处理器系统中，需要处理大端处理器对小端外设的访问。
十、实际中的例子

       虽然很多时候，字节序的工作已由编译器完成了，但是在一些小的细节上，仍然需要去仔细揣摩考虑，尤其是在以太网通讯、MODBUS通讯、软件移植性方面。这里，举一个MODBUS通讯的例子。在MODBUS中，数据需要组织成数据报文，该报文中的数据都是大端模式，即低地址存高位，高地址存低位。假设有一16位缓冲区m_RegMW[256]，因为是在x86平台上，所以内存中的数据为小端模式：m_RegMW[0].low、m_RegMW[0].high、m_RegMW[1].low、m_RegMW[1].high……
为了方便讨论，假设m_RegMW[0] = 0x3456; 在内存中为0x56、0x34。
       现要将该数据发出，如果不进行数据转换直接发送，此时发送的数据为0x56,0x34。而Modbus是大端的，会将该数据解释为0x5634而非原数据0x3456，此时就会发生灾难性的错误。所以，在此之前，需要将小端数据转换成大端的，即进行高字节和低字节的交换，此时可以调用步骤五中的函数BigtoLittle16(m_RegMW[0])，之后再进行发送才可以得到正确的数据。
```

